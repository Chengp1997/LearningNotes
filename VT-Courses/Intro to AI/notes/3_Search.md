# Search

å‚è€ƒé“¾æ¥ 

https://www.redblobgames.com/pathfinding/a-star/introduction.html A*ç®—æ³•ä»‹ç»

https://aimacode.github.io/aima-javascript/3-Solving-Problems-By-Searching/ æ¯ä¸ªæœç´¢ç®—æ³•å›¾ç¤ºè¯¦è§£

https://www.redblobgames.com/pathfinding/a-star/implementation.html implementation

## Definition

### Task Environment 

é¢ä¸´çš„å„ç§é—®é¢˜

-  Observability (Full or partially or unobservable) 
-   Single-agent or multi-agent
-   Deterministic or nondeterministic or stochastic
-   Episodic or sequential
-   Static or dynamic or semi-dynamic
-   Discrete or continuous
-   Known or unknown

### **Problem-soving agent**

å®šä½é—®é¢˜-æ‰¾åˆ°ç›®æ ‡ï¼Œå½¢æˆè§£å†³æ–¹æ¡ˆ

- agents that plan ahead

- **Atomic** presentation
  - states of the world are considered as whole
  - No internal structure visible to the problem-solving algorithms

### Search problem and solutions

è¦ç´ 

- A **state space** (a set **S**)
- Initial state (Start state *s*) åˆå§‹çŠ¶æ€
- Goal state(*s*) ç›®æ ‡çŠ¶æ€
- Actions(*s*): (a set **A**) å‰åå·¦å³
- Transition model: RESULT(s, a) è½¬æ¢çŠ¶æ€
- Action cost function: Action-Cost(s, a, sâ€™) èŠ±è´¹

solutionï¼šsequence of actions (**path**) from the initial state to a goal state

optimal solutionï¼š**lowest path cost** among solutions

### State Space Graph 

- æ˜¯æ­¤ç±»é—®é¢˜çš„ä¸€ç§æ•°å­¦åŒ–çš„å±•ç¤º
  - â€“  Nodes are world configurations (abstracted)
  - â€“  Arcs represent successors (action results)
  - â€“  The goal test is a set of goal nodes (maybe only one)
- **In a search graph, each state occurs only once.**

### Search Tree

- æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯state spaceä¸­çš„ä¸€ä¸ªçŠ¶æ€
- start stateæ˜¯root
- æ¯æ¡è¾¹ä»£è¡¨ç€ä¸€ä¸ªaction
- Each node encodes an entire path and correspond to plans to achieve that state

<img src="notePicture/ssgVSst.png" alt="image-20220125123149090" style="zoom:50%;" />

### Search Algorithms

- Input: Search problem
- Output: solution or an indication of failure
- Superimpose a **searchtree** over the **statespace graph**

### Algorithms's performance

- **Completeness**:Guaranteed to find a solution if one exists or correctly report failure æ˜¯å¦èƒ½ä¿è¯æ‰¾åˆ°æ–¹æ¡ˆ

- **Cost optimality**:Find the lowest path cost solution æ”¶å¦èƒ½æ‰¾åˆ°æœ€ä½³æ–¹æ¡ˆ

- Time complexity:Number of operations to find the solution

  â€“ b, maximum branching factor of search tree

  â€“ d, depth of the shallowest goal node

  â€“ m, maximum length of any path in the state space (potentially âˆ)

- Space complexity:Among of memory needed to find the solution

## Uninformed search

agent æ— æ³•çŸ¥é“åˆ°è¾¾goaléœ€è¦èŠ±è´¹å¤šå°‘ï¼Œå¯ä»¥ç†è§£ä¸ºï¼Œblind search

uninformedçš„ç®—æ³•è™½ç„¶å¯ä»¥è·å¾—æœ€ä½³ï¼Œä½†æ˜¯å¯èƒ½ä¼šé€Ÿåº¦éå¸¸æ…¢

### BFS

ä¸€èˆ¬ä½¿ç”¨**queue**æ¥å®ç°

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/breath-first.png" alt="image-20220125084311127" style="zoom:50%;" />

```python
# æ”¹è¿›ï¼Œè®°å½•æ¥çš„è·¯å¾„
frontier = Queue()
frontier.put(start )
came_from = dict()
came_from[start] = None

while not frontier.empty():
   current = frontier.get()
   if current == goal: # ç»ˆæ­¢æ¡ä»¶ï¼Œå¦‚æœæ‰¾åˆ°äº†èŠ‚ç‚¹ï¼Œå°±åœæ­¢ã€‚
     break 
   for next in graph.neighbors(current):
      if next not in came_from:
         frontier.put(next)
         came_from[next] = current # è®°å½•äº†å‰ä¸€ä¸ªèŠ‚ç‚¹

# é‡æ„è·¯å¾„
current = goal 
path = []
while current != start: 
   path.append(current)
   current = came_from[current]
path.append(start) # optional
path.reverse() # optional
```



#### Bi-direct	BFS

BFSçš„å‡çº§ï¼Œåªæ˜¯ä»ä¸¤ä¸ªç«¯ç‚¹å¼€å§‹ï¼Œ2*b^(d/2)

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/bidirection search.png" alt="image-20220126012600510" style="zoom:50%;" />

### DFS

ä¸€èˆ¬ä½¿ç”¨**stack**æ¥å®ç°

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/depth-first.png" alt="image-20220125084547818" style="zoom:50%;" />

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/depth-first tree.png" alt="image-20220125084614494" style="zoom:50%;" />

#### DFS limited

DFS with a depth limit L(ä¸€èˆ¬æ˜¯æ ¹æ®ç»éªŒæ¥å®šä¹‰L) ä¸€èˆ¬è¿™ä¸ªLä¸‹ï¼Œèƒ½å¤Ÿæ‰¾åˆ°æœ€å¥½çš„è·¯å¾„

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/Depth limited search.png" alt="image-20220126012234661" style="zoom:50%;" />

#### DFS iterative

Depth-limited search with depth L=1,L=2â€¦â€¦

è¿™ä¸ªç®—æ³•ä¸€èˆ¬æ˜¯ç”¨æ¥å¯»æ‰¾dfsçš„depth limitçš„

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/iterative deepening search.png" alt="image-20220126012514243" style="zoom:50%;" />

### UCS(Dijkstra) åŸºäºæˆæœ¬çš„

ä½¿ç”¨**priority queue**

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/uniform cost search.png" alt="image-20220126012657632" style="zoom:50%;" />

```python
# Dijkstra
frontier = PriorityQueue() # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—, ç›®çš„æ˜¯ä¸ºäº†å¯»æ‰¾æˆæœ¬æœ€å°çš„é‚£ä¸€æ¡è·¯
frontier.put(start, 0)
came_from = dict() # è®°å½•äº†è®¿é—®è¿‡çš„èŠ‚ç‚¹ï¼Œå½¢å¼ èŠ‚ç‚¹ï¼Œå‰ç½®èŠ‚ç‚¹
cost_so_far = dict() # è®°å½•åˆ°è¿™ä¸ªèŠ‚ç‚¹æ‰€èŠ±é”€çš„æœ€çŸ­çš„è·¯å¾„çš„æˆæœ¬å€¼
came_from[start] = None # åˆå§‹åŒ–
cost_so_far[start] = 0

while not frontier.empty():
   current = frontier.get()

   if current == goal:
      break
   
   for next in graph.neighbors(current):
      new_cost = cost_so_far[current] + graph.cost(current, next) # è®°å½•é‚»å±…è·¯å¾„æˆæœ¬å€¼
      if next not in cost_so_far or new_cost < cost_so_far[next]: #å¦‚æœæ¥ä¸‹æ¥çš„è¿™ä¸ªèŠ‚ç‚¹ï¼Œæ²¡æœ‰è¢«è®¿é—®è¿‡/æ‰€èŠ±è´¹çš„æˆæœ¬æ›´å°
         cost_so_far[next] = new_cost # æ›´æ–°å½“å‰æˆæœ¬å€¼
         priority = new_cost 
         frontier.put(next, priority)
         came_from[next] = current

```



### Summary

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/evaluation search.png" alt="image-20220126015615270" style="zoom:50%;" />

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/implementation.png" alt="image-20220129020818343" style="zoom:50%;" />



## Search-informed

- Uses domain-specific knowledge (**hints)**
- Can find solutions **more efficiently**
- **Heuristic**: Lead the search algorithm faster towards a goal state.
  - Implemented via **Heuristic** function: h(n)

### **Heuristics function**

estimated cost of the **cheapest** path from the state at node n to goal state

ç”¨æ¥ä¼°ç®—å½“å‰çŠ¶æ€åˆ°ç›®æ ‡ç‚¹çš„èŠ±é”€ã€‚

å¯ä»¥å°†è¿™ä¸ªåº”ç”¨åˆ°ç®—æ³•ä¸­

ä¾‹å¦‚ä½¿ç”¨ï¼šæ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œæ›¼å“ˆé¡¿è·ç¦»ï¼Œç›´çº¿è·ç¦»ç­‰

å¦‚æœåªèƒ½ä¸Šä¸‹å·¦å³ï¼Œå¯ä»¥ä½¿ç”¨æ›¼å“ˆé¡¿è·ç¦»ã€‚

å¦‚æœå¯ä»¥ä»»æ„æ–¹å‘ç§»åŠ¨ï¼Œå¯ä»¥ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚

### **Greedy best-first search**

- Strategy: expand a **node with the lowest h(n)value** æ¯æ¬¡éƒ½ä½¿ç”¨æœ€çŸ­è·ç¦»

- å¾ˆåƒ UCS+priority queue(difference:use estimated forward cost, not computed backward cost) åŒºåˆ«åœ¨äºï¼Œè¿™ä¸ªæ–¹æ³•è®¡ç®—çš„æ˜¯æ¯æ¬¡åˆ°è¾¾ç»ˆç‚¹çš„è·ç¦»ï¼Œucsè®¡ç®—çš„æ˜¯å½“å‰ä»å‡ºå‘åˆ°è¯¥ç‚¹çš„è·ç¦»ã€‚

- **Not optimal!**
- Could not find the best solution. 
- å¦‚æœé€‰æ‹©çš„è·ç¦»æ–¹ç¨‹è¾ƒå·®ï¼Œç”šè‡³æœ‰å¯èƒ½æ‰¾ä¸åˆ°solution

```python
# Heuristic function
def heuristic(a, b):
   # Manhattan distance on a square grid
   return abs(a.x - b.x) + abs(a.y - b.y)

frontier = PriorityQueue()
frontier.put(start, 0)
came_from = dict()
came_from[start] = None

while not frontier.empty():
   current = frontier.get()

   if current == goal:
      break
   
   for next in graph.neighbors(current):
      if next not in came_from:
         priority = heuristic(goal, next) #é€šè¿‡heuristic æ–¹ç¨‹æ¥è®¡ç®—æˆæœ¬
         frontier.put(next, priority)
         came_from[next] = current
```



### A *

Dijkstra ç®—æ³•è™½ç„¶èƒ½å¤Ÿæ‰¾åˆ°èŠ±é”€æœ€å°çš„è·¯å¾„ï¼Œä½†æ˜¯èŠ±äº†å¤ªå¤šçš„æ—¶é—´åœ¨ä¸€äº›ä¸ç»ˆç‚¹ä¸é¡ºçš„æ–¹å‘ä¸Šçš„èŠ‚ç‚¹ä¸Šã€‚

Greedyè™½ç„¶æ–¹å‘æ­£ç¡®äº†ï¼Œä½†æ˜¯å¯èƒ½æ‰¾ä¸åˆ°æœ€çŸ­è·¯å¾„ã€‚

å› æ­¤å°†è¿™ä¸¤ä¸ªç‰¹æ€§ç»“åˆï¼

**cost optimal!**

- **UCS+Greedy**
  - UCSè®¡ç®—çš„æ˜¯æ¥ç¨‹çš„æˆæœ¬
  - Greedyè®¡ç®—çš„æ˜¯åˆ°ç»ˆç‚¹çš„èŠ±é”€
  - ç»“åˆç»¼åˆè€ƒè™‘æ€»çš„æˆæœ¬ï¼Œä»è€Œæ¥è¿›è¡Œã€‚

- **f(n)=g(n)+h(n)**:lowest estimated cost of the path from n to G
  - g(n):path cost from the initial state to node n(ç›´çº¿è·ç¦»)
  - h(n): path cost from state to goal
  - ç»“åˆè¯¥ç‚¹åˆ°ç»ˆç‚¹å’Œ
- Uses **priority queue**
- completenessï¼šYes
- cost optimal: å–å†³äº **properties** **of the heuristic ** åªæœ‰ä¿è¯è¿™äº›ç‰¹æ€§ï¼Œè¿™ä¸ªç®—æ³•æ‰æ˜¯cost-optimalçš„
  - **properties** **of the heuristic**ï¼š heuristic costs <=actual costs
    - **Admissibility**ï¼ˆå¯æ¥çº³çš„ï¼‰: admissible (optimistic) heuristic never overestimates the cost**. 0<= h(ğ‘›)<=h*(ğ‘›)**  ï¼ˆå¯å‘å‡½æ•°ä¼°ç®—æˆæœ¬è¦<=å®é™…è·¯å¾„åˆ°è¾¾goalçš„æˆæœ¬ï¼‰
    - **Consistency**ï¼ˆä¸€è‡´æ€§ï¼‰**: h(ğ‘›) <= h(ğ‘›â€²) + cost(n, a, nâ€™)** ï¼ˆå¯å‘å‡½æ•°æ¯æ¡è¾¹çš„çš„ä¼°ç®—æˆæœ¬<=æ¯æ¡è¾¹çš„å®é™…æˆæœ¬ï¼‰
    - **Consistent heuristic is admissible**

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/heuristic.png" alt="image-20220129165459289" style="zoom:50%;" />

<img src="/Users/chengeping/Documents/LearningMaterial/VTNote/CS5804 Intro to AI/note/notePicture/admissibility&consistency.png" alt="image-20220129182743968" style="zoom:50%;" />

â€‹	ï¼ï¼å¦‚æœä¸å¯æ¥çº³ï¼ˆå³ä¼°ç®—åæˆæœ¬æ¯”å®é™…è¿˜é«˜ï¼Œå¯èƒ½å¹¶ä¸ä¼šcost -optimaï¼‰

```python
# Heuristic function
def heuristic(a, b):
   # Manhattan distance on a square grid
   return abs(a.x - b.x) + abs(a.y - b.y)

frontier = PriorityQueue()
frontier.put(start, 0)
came_from = dict()
cost_so_far = dict()
came_from[start] = None
cost_so_far[start] = 0

while not frontier.empty():
   current = frontier.get()

   if current == goal:
      break
   
   for next in graph.neighbors(current):
      new_cost = cost_so_far[current] + graph.cost(current, next)
      if next not in cost_so_far or new_cost < cost_so_far[next]:
         cost_so_far[next] = new_cost
         priority = new_cost + heuristic(goal, next)
         frontier.put(next, priority)
         came_from[next] = current
```



### Weighted A* (suboptimal search)

- **f(n)=g(n)+W*****h(n)(W>1) **åŠ äº†æƒé‡

  - a slightly costlier, but could search faster æˆæœ¬å¯èƒ½ä¼šç•¥é«˜ï¼Œä½†æ˜¯èƒ½å¤Ÿæœç´¢å¾—æ›´å¿«

  - optimal path would not be found 

  - Cost of weighted A* search:between C* and WxC*

| **A\* search**     | **g(n) + h(n)** | **W=1** |
| ------------------ | --------------- | ------- |
| UCS search         | g(n)            | W=0     |
| Greedy search      | h(n)            |         |
| Weighted A* search | g(n) + W x h(n) | W>1     |

### Memory-bounded Search

- Beam search:limits the size of the frontier
- Iterative-deepening A* search(IDA*)
- Bidirectional A*
- recursive best-first search
- simplified memory-bounded A*



## Summary

#### Which to use

Which algorithm should you use for finding paths on a game map?

- If you want to find paths **from or to *all* all locations**, use **BFS** or **Dijkstra**. 
  - Use **BFS** if movement costs **are all the same**; 
  - use Dijkstra if movement costs **vary**.
- If you want to find paths **to *one* location**, or the **closest of several goals**, use **Greedy Best First Search** or **A****. Prefer **A****in most cases. When youâ€™re tempted to use Greedy Best First Search, consider using A* with an [â€œinadmissibleâ€ heuristic](https://en.wikipedia.org/wiki/Admissible_heuristic).

#### Optimal path

**BFS** and **Dijkstra** are **guaranteed to find the shortest path** given the input graph. 

**Greedy Best First Search is not**. 

A* is **guaranteed to find the shortest path** if the **heuristic is never larger than the true distance.** As the heuristic becomes smaller, A* turns into Dijkstraâ€™s Algorithm. As the heuristic becomes larger, A* turns into Greedy Best First Search.

#### Performance

Greedy Best First Search **typically** runs faster than Dijkstraâ€™s Algorithm but doesnâ€™t produce optimal paths. **A* is a good choice for most pathfinding needs.**